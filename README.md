# REMINDâ€¢AR â€” Dementia Face Recognition Assistant

> **"Observe first, remember later, assist once truth is confirmed."**

An AR-style face recognition system that helps dementia patients remember the people in their lives. The system observes faces, records interactions, and only displays identity information after a caregiver has confirmed who the person is.

## ğŸ¯ Features

### Patient Mode
- **Real-time Face Detection** â€” MediaPipe-powered face tracking
- **AR-style HUD** â€” Glassmorphic overlay showing name, relation, and emotional cues
- **Memory Recording** â€” Audio recording with automatic transcription and summarization
- **Text-to-Speech** â€” Optional audio announcements for close family members

### Caregiver Mode
- **Review Pending People** â€” See all unconfirmed faces detected
- **Confirm Identities** â€” Assign names and relationships
- **Manage Memories** â€” View and edit recorded memories

## ğŸ—ï¸ Architecture

```
Frontend (React/Vite)          Backend (FastAPI)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Camera + MediaPipe  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ FaceNet (512-dim)   â”‚
â”‚ HUD Overlay         â”‚â—€â”€â”€â”€â”€â”€â”€â”‚ Groq LLM            â”‚
â”‚ Audio Recording     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Groq Whisper        â”‚
â”‚ Caregiver Panel     â”‚â—€â”€â”€â”€â”€â”€â–¶â”‚ Qdrant + Neo4j      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.10+
- Qdrant Cloud account
- Neo4j Cloud account
- Groq API key

### 1. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy and configure environment
cp .env.example .env
# Edit .env with your API keys

# Run the server
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

### 3. Access the App

- **Patient Mode:** http://localhost:5173
- **Caregiver Mode:** http://localhost:5173/caregiver
- **API Docs:** http://localhost:8000/docs

## ğŸ“¡ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/health` | GET | Health check |
| `/api/recognize-face` | POST | Recognize a face from image |
| `/api/hud-context` | POST | Get HUD content for a person |
| `/api/memory/save` | POST | Save memory from audio |
| `/api/caregiver/pending` | GET | Get pending people |
| `/api/caregiver/confirm` | POST | Confirm a person's identity |

## ğŸ” Key Principles

1. **No Identity Hallucination** â€” The LLM never guesses identities
2. **Caregiver Controls Truth** â€” Only caregivers can confirm identities
3. **TEMPORARY â†’ CONFIRMED** â€” New faces start as temporary until reviewed
4. **Privacy by Design** â€” No passive surveillance, explicit recording only

## ğŸ“ Project Structure

```
hackathon/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Camera, HUD, RecordButton
â”‚   â”‚   â”œâ”€â”€ hooks/          # useFaceTracking, useAudioRecorder
â”‚   â”‚   â”œâ”€â”€ pages/          # PatientMode, CaregiverMode
â”‚   â”‚   â””â”€â”€ services/       # API client
â”‚   â””â”€â”€ ...
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routers/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/       # FaceNet, LLM, Whisper, DBs
â”‚   â”‚   â””â”€â”€ models/         # Pydantic schemas
â”‚   â””â”€â”€ ...
â””â”€â”€ plan.xml                # System design document
```

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Frontend | React + Vite |
| Face Tracking | MediaPipe |
| Backend | FastAPI |
| Face Recognition | FaceNet (facenet-pytorch) |
| LLM | Groq (llama-3.3-70b) |
| Speech-to-Text | Groq Whisper |
| Text-to-Speech | Web Speech API |
| Vector DB | Qdrant |
| Graph DB | Neo4j |

## ğŸ“„ License

MIT License â€” Built for hackathon demo purposes.
